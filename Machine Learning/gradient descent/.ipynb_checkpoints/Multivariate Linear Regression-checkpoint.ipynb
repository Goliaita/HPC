{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression\n",
    "The dataset has the squared meters of the house and the number of bathrooms, while the third column represents the price of the houses.\n",
    "The problem here is the different scale of the features. The problem can be solved by **feature scaling**.\n",
    "\n",
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt('data/ex1data2.txt', delimiter=',')\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 47\n",
      "Features: 2\n",
      "10 examples: \n",
      " [[2.104e+03 3.000e+00]\n",
      " [1.600e+03 3.000e+00]\n",
      " [2.400e+03 3.000e+00]\n",
      " [1.416e+03 2.000e+00]\n",
      " [3.000e+03 4.000e+00]\n",
      " [1.985e+03 4.000e+00]\n",
      " [1.534e+03 3.000e+00]\n",
      " [1.427e+03 3.000e+00]\n",
      " [1.380e+03 3.000e+00]\n",
      " [1.494e+03 3.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "x = data[:, :2]\n",
    "y = data[:, -1]\n",
    "\n",
    "# from n-dimensional vector to m x 1 matrix\n",
    "y = np.reshape(y, (y.shape[0], 1))\n",
    "\n",
    "m = x.shape[0]\n",
    "print(\"Training examples: {}\".format(m))\n",
    "\n",
    "n = x.shape[1]\n",
    "print(\"Features: {}\".format(n))\n",
    "\n",
    "print(\"10 examples: \\n\", x[:10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features normalization\n",
    "From all the features do the following\n",
    "* Subtract the mean value\n",
    "* Didive by the std deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_normalize(x):\n",
    "    x_norm = x\n",
    "    \n",
    "    mu = np.zeros((1, x.shape[1]))\n",
    "    sigma = np.zeros((1, x.shape[1]))\n",
    "    \n",
    "    mu = np.mean(x, axis = 0) # mean value\n",
    "    sigma = np.std(x, axis = 0) # std deviation value\n",
    "    \n",
    "    for i in range(x.shape[1]):\n",
    "        x_norm[:,i] = (x[:,i] - mu[i])/sigma[i]\n",
    "        \n",
    "    return x_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 normalized examples: \n",
      " [[ 0.13141542 -0.22609337]\n",
      " [-0.5096407  -0.22609337]\n",
      " [ 0.5079087  -0.22609337]\n",
      " [-0.74367706 -1.5543919 ]\n",
      " [ 1.27107075  1.10220517]\n",
      " [-0.01994505  1.10220517]\n",
      " [-0.59358852 -0.22609337]\n",
      " [-0.72968575 -0.22609337]\n",
      " [-0.78946678 -0.22609337]\n",
      " [-0.64446599 -0.22609337]]\n",
      "Mean value: [2000.68085106    3.17021277]\n",
      "Standard deviation value: [7.86202619e+02 7.52842809e-01]\n"
     ]
    }
   ],
   "source": [
    "x_norm, mu, sigma = feature_normalize(x)\n",
    "print(\"10 normalized examples: \\n\", x_norm[:10, :])\n",
    "print(\"Mean value: {}\".format(mu))\n",
    "print(\"Standard deviation value: {}\".format(sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a column for dealing with all the parameters\n",
    "$h_{\\theta}(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 3)\n"
     ]
    }
   ],
   "source": [
    "x_norm = np.concatenate([np.ones((m,1)), x_norm], axis = 1) # Add the column of ones to the data examples (for $\\theta_0$) \n",
    "\n",
    "print(x_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce functions to compute cost and gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, theta, alpha = 0.1, iterations = 1500):\n",
    "    costs = []\n",
    "    for i in range(0, iterations):\n",
    "        theta = theta - (alpha / x.shape[0]) * (x.T).dot(x.dot(theta) - y)\n",
    "        costs.append(calculate_cost(x, y, theta))\n",
    "    return theta, costs\n",
    "\n",
    "def calculate_cost(x, y, theta = [[0],[0],[0]]):\n",
    "    h = x.dot(theta)\n",
    "    return 1/(2 * x.shape[0]) * np.sum(np.square(h - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non normalized theta: \n",
      " [[340412.65957447]\n",
      " [109447.79645983]\n",
      " [ -6578.35484435]]\n",
      "Normalized theta: \n",
      " [[340412.65957447]\n",
      " [109447.79645983]\n",
      " [ -6578.35484435]]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "num_iters = 500\n",
    "\n",
    "theta = np.zeros((3, 1))\n",
    "theta, cost_history = gradient_descent(x_norm, y, theta, alpha, num_iters)\n",
    "\n",
    "theta_no_norm = np.zeros((3, 1))\n",
    "x = np.concatenate([np.ones((m,1)), x], axis = 1)# Add column of ones to non normalized dataset\n",
    "theta_no_norm, cost_history_no_norm = gradient_descent(x, y, theta_no_norm, alpha, num_iters)\n",
    "\n",
    "print(\"Non normalized theta: \\n\", theta_no_norm)\n",
    "print(\"Normalized theta: \\n\", theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa8e91b9710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Plot the convergence graph\n",
    "plt.plot([i for i in range(num_iters)], cost_history, '-r', label = 'Normalized cost')\n",
    "plt.plot([i for i in range(num_iters)], cost_history_no_norm, '-b', label = 'Non normalized cost')\n",
    "plt.xlabel('Number of iterations') # Set the x−axis label\n",
    "plt.ylabel('Cost J') # Set the y−axis label \n",
    "plt.title('Cost behavior')\n",
    "plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the following next:\n",
    "* Modify the learning rate to a smaller number (.001)\n",
    "* Overshoot the minimum using a bigger learnin rate (1)\n",
    "* As starting point, use np.array([1,2,3]) for theta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[340412.65957447],\n",
       "       [109447.79645983],\n",
       "       [ -6578.35484435]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
